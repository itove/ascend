# Journal-20251031

## Create LVM on gx2, gx3, gx4
* Create 2 PVs: `/dev/nvme0n1` 3.5T, `/dev/nvme1n1` 3.5T
* Create a VG, name `elwynn`, use all PVs
* Create a LV, name `stromwind`, use all space on VG `elwynn`
* Create `xfs` filesystem on LV `stromwind`
* Mount LV `stromwind` on `/mnt/d`, total size 7.0T

## On gx3, rsync data from gx1 to gx3
```
[al@gx3 ~]$ sudo rsync -avP /mnt/data/* /mnt/d/
```
```
[al@gx3 ~]$ sudo rsync -avP /mnt/data2/* /mnt/d/models/
```

## Test workflow using data in /mnt/d on gx3
**On gx3**, NFS share `/mnt/d`  
Edit `/etc/exports`, add:
```
/mnt/d *(rw,no_root_squash)
```
**On gx1, gx2, gx4**, mount `gx3:/mnt/d` at `/mnt/gx3`
```
$ sudo mkdir /mnt/gx3
$ sudo mount 172.20.84.189:/mnt/d /mnt/gx3
```
**On gx3**, create symlink `/mnt/gx3` -> `/mnt/d`, so all 4 hosts can use the same path `/mnt/gx3`
```
[al@gx3 ~]$ cd /mnt
[al@gx3 ~]$ sudo ln -s d gx3
```

Edit `bin/docker-run.sh` and `bin/run-in-container.sh`
```diff
diff --git a/bin/docker-run.sh b/bin/docker-run.sh
index f2543c9..b887cbb 100755
--- a/bin/docker-run.sh
+++ b/bin/docker-run.sh
@@ -35,8 +35,7 @@ docker run -itd --user root --privileged --rm --name=$name --net=host \
    -v /usr/local/sbin/npu-smi:/usr/local/sbin/npu-smi \
    -v /usr/local/sbin:/usr/local/sbin \
    -v /etc/hccn.conf:/etc/hccn.conf \
-   -v /mnt/data:/data \
-   -v /mnt/data2:/data2 \
+   -v /mnt/gx3:/data \
    swr.cn-south-1.myhuaweicloud.com/ascendhub/mindie:$tag \
    bash

diff --git a/bin/run-in-container.sh b/bin/run-in-container.sh
index b3ff737..a340975 100755
--- a/bin/run-in-container.sh
+++ b/bin/run-in-container.sh
@@ -4,16 +4,16 @@
 #
 # example:
 # run signle node for small model with **custom** config.json
-# CONF_PATH=/config.json MULTI=0 MODEL_PATH=/data/hf/models/DeepSeek-R1-Distill-Llama-8B /data/run-in-container.sh
+# CONF_PATH=/data/conf/config-1.json MULTI=0 MODEL_PATH=/data/hf/deepseek-ai/DeepSeek-R1-Distill-Llama-8B /data/run-in-container.sh
 #
 # run multi nodes for large model with **default** config.json
-# MODEL_PATH=DeepSeek-V3 /data/run-in-container.sh
+# MODEL_PATH=/data/hf/deepseek-ai/DeepSeek-R1-Distill-Llama-8B /data/run-in-container.sh

 set -e

-CONF_PATH=${CONF_PATH:-/data/config.json}
+CONF_PATH=${CONF_PATH:-/data/conf/config.json}
 MULTI=${MULTI:-1}
-MODEL_PATH=${MODEL_PATH:-/data2/hf/models/DeepSeek-V3}
+MODEL_PATH=${MODEL_PATH:-/data/models/deepseek-v3-0324-bf16}

diff --git a/bin/run-in-container.sh b/bin/run-in-container.sh
index a340975..de2ea94 100755
--- a/bin/run-in-container.sh
+++ b/bin/run-in-container.sh
@@ -79,7 +79,7 @@ unset RANKTABLEFILE # 2.0
 export MIES_CONTAINER_IP=${addr[$HOSTNAME]}

 if [ $MULTI -eq 1 ]; then
-    export RANK_TABLE_FILE=/data/rank_table.json
+    export RANK_TABLE_FILE=/data/conf/rank_table.json
```

Run MindIE service, SUCCESS.

## Umount /mnt/data and /mnt/data2
**On gx2, gx3, gx4**, umount `/mnt/data` and `/mnt/data2`
```
$ sudo umount /mnt/data
umount.nfs4: /mnt/data: device is busy
```

Use `-l` option
```
$ sudo umount -l /mnt/data
$ sudo umount -l /mnt/data2
```
After `umount -l ...`, `ls /mnt` and `ls /mnt/gx3` hang, didn't figure out why. But on gx3, restart nfs fixed it.

**On gx1**, umount `/mnt/data` and `/mnt/data2`
```
[al@gx1 ~]$ sudo umount /mnt/data2
umount: /mnt/data2: target is busy
```

Use `-l` option
```
[al@gx1 ~]$ sudo umount -l /mnt/data
[al@gx1 ~]$ sudo umount -l /mnt/data2
```
Delete entries of `/mnt/data` and `/mnt/data2` in `/etc/fstab`

## Create LVM on gx1
Remove filesystem on `/dev/nvme0n1` and `/dev/nvme1n1` (**unnecessary**)
```
[al@gx1 ~]$ sudo wipefs -a /dev/nvme0n1
wipefs: error: /dev/nvme0n1: probing initialization failed: Device or resource busy
```
Reboot system, and try again.
```
[al@gx1 ~]$ sudo wipefs -a /dev/nvme1n1
/dev/nvme1n1: 4 bytes were erased at offset 0x00000000 (xfs): 58 46 53 42
[al@gx1 ~]$ sudo wipefs -a /dev/nvme0n1
/dev/nvme0n1: 4 bytes were erased at offset 0x00000000 (xfs): 58 46 53 42
```
Create LVM
```
[al@gx1 ~]$ sudo mount 172.20.84.189:/mnt/d /mnt/gx3
[al@gx1 ~]$ /mnt/gx3/bin/lvm.sh
DANGEROUS!!!
You are about to create a new filesystem, which will DESTROY your data on /dev/nvme0n1 /dev/nvme1n1!!!
Sure you wanna do this?
Type YES to confirm. [YES/n] YES
Creating PVs for disks: /dev/nvme0n1 /dev/nvme1n1
  Physical volume "/dev/nvme0n1" successfully created.
  Physical volume "/dev/nvme1n1" successfully created.
Create VG elwynn
  Volume group "elwynn" successfully created
Creating LV stromwind
WARNING: atari signature detected on /dev/elwynn/stromwind at offset 478. Wipe it? [y/n]: y
  Wiping atari signature on /dev/elwynn/stromwind.
WARNING: atari signature detected on /dev/elwynn/stromwind at offset 490. Wipe it? [y/n]: y
  Wiping atari signature on /dev/elwynn/stromwind.
  Logical volume "stromwind" created.
Creating xfs filesystem...
meta-data=/dev/elwynn/stromwind  isize=512    agcount=7, agsize=268435455 blks
         =                       sectsz=512   attr=2, projid32bit=1
         =                       crc=1        finobt=1, sparse=1, rmapbt=0
         =                       reflink=1
data     =                       bsize=4096   blocks=1875367936, imaxpct=5
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0, ftype=1
log      =internal log           bsize=4096   blocks=521728, version=2
         =                       sectsz=512   sunit=0 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0
Discarding blocks...Done.
Created: /dev/elwynn/stromwind UUID: da50973c-8cd0-40d1-a43f-2cd1b4941f0a
Creating mountpoint: /mnt/d
Append to /etc/fstab...
Mounting...
```

## rsync /mnt/d/models on gx3 to gx1, gx2, gx4
**On gx1, gx2, gx4**, run
```
$ sudo rsync -avP /mnt/gx3/models /mnt/d/
```
