INFO: Detected Ascend NPU
INFO: current model_type: pa_bf16
INFO: current test_mode: full_CEval
INFO: use shot: 5
INFO: current batch_size: 1
INFO: current model_name: deepseekv2
INFO: current weight_dir: /data2/hf/models/deepseek-v3-bf16/
INFO: current model_type: pa
INFO: current data_type: bf16
INFO: current test_mode: full
INFO: current dataset: CEval
INFO: current trust_remote_code: False
INFO: current using multiple node, use rank table file: /data/rank_table.json
INFO: current world_size: 32
INFO: current node_num: 4
INFO: current local_world_size: 8
INFO: current rank_id_start: 24
INFO: current node_rank: 3
INFO: current master_addr: 172.20.84.67
/usr/local/lib/python3.11/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning
  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')
[2025-10-28 16:42:44,313] [38739] [281460966443296] [llm] [INFO] [model_test.py-524] : 
model_name: deepseekv2
model_type: pa
data_type: bf16
test_mode: full
data_dir: /usr/local/Ascend/atb-models/tests/modeltest/outputs/data/NPU/precision_test/full/bf16/deepseekv2
time_limit: 0
batch_size: 1
result_dir: /usr/local/Ascend/atb-models/tests/modeltest/outputs/results/NPU/precision_test/full/bf16/deepseekv2
log_dir: /usr/local/Ascend/atb-models/tests/modeltest/outputs/logs
[2025-10-28 16:42:44,319] [38739] [281460966443296] [llm] [INFO] [model_test.py-543] : ATB env get success.
[2025-10-28 16:42:44,319] [38739] [281460966443296] [llm] [INFO] [model_test.py-548] : ATB_SPEED env get success
[2025-10-28 16:42:44,319] [38739] [281460966443296] [llm] [WARNING] [model_test.py-564] : deepseekv2 not support CEval, please check
/usr/local/lib/python3.11/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning
  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')
[2025-10-28 16:42:44,322] [38739] [281460966443296] [llm] [INFO] [model_test.py-861] : precision test start
/usr/local/lib/python3.11/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning
  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')
/usr/local/lib/python3.11/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning
  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')
/usr/local/lib/python3.11/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning
  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')
/usr/local/lib/python3.11/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning
  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')
/usr/local/lib/python3.11/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning
  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')
/usr/local/lib/python3.11/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning
  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')
[2025-10-28 16:42:44,489] [38736] [281459463375136] [llm] [INFO] [model_test.py-524] : 
model_name: deepseekv2
model_type: pa
data_type: bf16
test_mode: full
data_dir: /usr/local/Ascend/atb-models/tests/modeltest/outputs/data/NPU/precision_test/full/bf16/deepseekv2
time_limit: 0
batch_size: 1
result_dir: /usr/local/Ascend/atb-models/tests/modeltest/outputs/results/NPU/precision_test/full/bf16/deepseekv2
log_dir: /usr/local/Ascend/atb-models/tests/modeltest/outputs/logs
[2025-10-28 16:42:44,495] [38736] [281459463375136] [llm] [INFO] [model_test.py-543] : ATB env get success.
[2025-10-28 16:42:44,495] [38736] [281459463375136] [llm] [INFO] [model_test.py-548] : ATB_SPEED env get success
[2025-10-28 16:42:44,495] [38736] [281459463375136] [llm] [WARNING] [model_test.py-564] : deepseekv2 not support CEval, please check
[2025-10-28 16:42:44,497] [38736] [281459463375136] [llm] [INFO] [model_test.py-861] : precision test start
[2025-10-28 16:42:44,554] [38743] [281473109477664] [llm] [INFO] [model_test.py-524] : 
model_name: deepseekv2
model_type: pa
data_type: bf16
test_mode: full
data_dir: /usr/local/Ascend/atb-models/tests/modeltest/outputs/data/NPU/precision_test/full/bf16/deepseekv2
time_limit: 0
batch_size: 1
result_dir: /usr/local/Ascend/atb-models/tests/modeltest/outputs/results/NPU/precision_test/full/bf16/deepseekv2
log_dir: /usr/local/Ascend/atb-models/tests/modeltest/outputs/logs
[2025-10-28 16:42:44,560] [38743] [281473109477664] [llm] [INFO] [model_test.py-543] : ATB env get success.
[2025-10-28 16:42:44,560] [38743] [281473109477664] [llm] [INFO] [model_test.py-548] : ATB_SPEED env get success
[2025-10-28 16:42:44,560] [38743] [281473109477664] [llm] [WARNING] [model_test.py-564] : deepseekv2 not support CEval, please check
[2025-10-28 16:42:44,563] [38743] [281473109477664] [llm] [INFO] [model_test.py-861] : precision test start
[2025-10-28 16:42:44,563] [38741] [281467961035040] [llm] [INFO] [model_test.py-524] : 
model_name: deepseekv2
model_type: pa
data_type: bf16
test_mode: full
data_dir: /usr/local/Ascend/atb-models/tests/modeltest/outputs/data/NPU/precision_test/full/bf16/deepseekv2
time_limit: 0
batch_size: 1
result_dir: /usr/local/Ascend/atb-models/tests/modeltest/outputs/results/NPU/precision_test/full/bf16/deepseekv2
log_dir: /usr/local/Ascend/atb-models/tests/modeltest/outputs/logs
[2025-10-28 16:42:44,569] [38741] [281467961035040] [llm] [INFO] [model_test.py-543] : ATB env get success.
[2025-10-28 16:42:44,569] [38741] [281467961035040] [llm] [INFO] [model_test.py-548] : ATB_SPEED env get success
[2025-10-28 16:42:44,569] [38738] [281471732959520] [llm] [INFO] [model_test.py-524] : 
model_name: deepseekv2
model_type: pa
data_type: bf16
test_mode: full
data_dir: /usr/local/Ascend/atb-models/tests/modeltest/outputs/data/NPU/precision_test/full/bf16/deepseekv2
time_limit: 0
batch_size: 1
result_dir: /usr/local/Ascend/atb-models/tests/modeltest/outputs/results/NPU/precision_test/full/bf16/deepseekv2
log_dir: /usr/local/Ascend/atb-models/tests/modeltest/outputs/logs
[2025-10-28 16:42:44,569] [38741] [281467961035040] [llm] [WARNING] [model_test.py-564] : deepseekv2 not support CEval, please check
[2025-10-28 16:42:44,573] [38741] [281467961035040] [llm] [INFO] [model_test.py-861] : precision test start
[2025-10-28 16:42:44,571] [38742] [281468354578720] [llm] [INFO] [model_test.py-524] : 
model_name: deepseekv2
model_type: pa
data_type: bf16
test_mode: full
data_dir: /usr/local/Ascend/atb-models/tests/modeltest/outputs/data/NPU/precision_test/full/bf16/deepseekv2
time_limit: 0
batch_size: 1
result_dir: /usr/local/Ascend/atb-models/tests/modeltest/outputs/results/NPU/precision_test/full/bf16/deepseekv2
log_dir: /usr/local/Ascend/atb-models/tests/modeltest/outputs/logs
[2025-10-28 16:42:44,573] [38740] [281470569695520] [llm] [INFO] [model_test.py-524] : 
model_name: deepseekv2
model_type: pa
data_type: bf16
test_mode: full
data_dir: /usr/local/Ascend/atb-models/tests/modeltest/outputs/data/NPU/precision_test/full/bf16/deepseekv2
time_limit: 0
batch_size: 1
result_dir: /usr/local/Ascend/atb-models/tests/modeltest/outputs/results/NPU/precision_test/full/bf16/deepseekv2
log_dir: /usr/local/Ascend/atb-models/tests/modeltest/outputs/logs
[2025-10-28 16:42:44,574] [38738] [281471732959520] [llm] [INFO] [model_test.py-543] : ATB env get success.
[2025-10-28 16:42:44,574] [38738] [281471732959520] [llm] [INFO] [model_test.py-548] : ATB_SPEED env get success
[2025-10-28 16:42:44,575] [38738] [281471732959520] [llm] [WARNING] [model_test.py-564] : deepseekv2 not support CEval, please check
[2025-10-28 16:42:44,575] [38737] [281461271775520] [llm] [INFO] [model_test.py-524] : 
model_name: deepseekv2
model_type: pa
data_type: bf16
test_mode: full
data_dir: /usr/local/Ascend/atb-models/tests/modeltest/outputs/data/NPU/precision_test/full/bf16/deepseekv2
time_limit: 0
batch_size: 1
result_dir: /usr/local/Ascend/atb-models/tests/modeltest/outputs/results/NPU/precision_test/full/bf16/deepseekv2
log_dir: /usr/local/Ascend/atb-models/tests/modeltest/outputs/logs
[2025-10-28 16:42:44,576] [38738] [281471732959520] [llm] [INFO] [model_test.py-861] : precision test start
[2025-10-28 16:42:44,577] [38742] [281468354578720] [llm] [INFO] [model_test.py-543] : ATB env get success.
[2025-10-28 16:42:44,577] [38742] [281468354578720] [llm] [INFO] [model_test.py-548] : ATB_SPEED env get success
[2025-10-28 16:42:44,577] [38742] [281468354578720] [llm] [WARNING] [model_test.py-564] : deepseekv2 not support CEval, please check
[2025-10-28 16:42:44,578] [38740] [281470569695520] [llm] [INFO] [model_test.py-543] : ATB env get success.
[2025-10-28 16:42:44,579] [38740] [281470569695520] [llm] [INFO] [model_test.py-548] : ATB_SPEED env get success
[2025-10-28 16:42:44,579] [38740] [281470569695520] [llm] [WARNING] [model_test.py-564] : deepseekv2 not support CEval, please check
[2025-10-28 16:42:44,580] [38742] [281468354578720] [llm] [INFO] [model_test.py-861] : precision test start
[2025-10-28 16:42:44,580] [38737] [281461271775520] [llm] [INFO] [model_test.py-543] : ATB env get success.
[2025-10-28 16:42:44,580] [38737] [281461271775520] [llm] [INFO] [model_test.py-548] : ATB_SPEED env get success
[2025-10-28 16:42:44,580] [38737] [281461271775520] [llm] [WARNING] [model_test.py-564] : deepseekv2 not support CEval, please check
[2025-10-28 16:42:44,582] [38737] [281461271775520] [llm] [INFO] [model_test.py-861] : precision test start
[2025-10-28 16:42:44,581] [38740] [281470569695520] [llm] [INFO] [model_test.py-861] : precision test start
[2025-10-28 16:42:49,390] [38736] [281459463375136] [llm] [INFO] [cpu_binding.py-212] : rank_id: 0, device_id: 0, numa_id: 3, shard_devices: [0, 1], cpus: [144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191]
[2025-10-28 16:42:49,393] [38736] [281459463375136] [llm] [INFO] [cpu_binding.py-238] : process 38736, new_affinity is [144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167], cpu count 24
[2025-10-28 16:42:49,394] [38739] [281460966443296] [llm] [INFO] [cpu_binding.py-212] : rank_id: 3, device_id: 3, numa_id: 2, shard_devices: [2, 3], cpus: [96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143]
[2025-10-28 16:42:49,397] [38739] [281460966443296] [llm] [INFO] [cpu_binding.py-238] : process 38739, new_affinity is [120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143], cpu count 24
[2025-10-28 16:42:49,501] [38743] [281473109477664] [llm] [INFO] [cpu_binding.py-212] : rank_id: 7, device_id: 7, numa_id: 1, shard_devices: [6, 7], cpus: [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]
[2025-10-28 16:42:49,503] [38743] [281473109477664] [llm] [INFO] [cpu_binding.py-238] : process 38743, new_affinity is [72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95], cpu count 24
[2025-10-28 16:42:49,509] [38738] [281471732959520] [llm] [INFO] [cpu_binding.py-212] : rank_id: 2, device_id: 2, numa_id: 2, shard_devices: [2, 3], cpus: [96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143]
[2025-10-28 16:42:49,512] [38738] [281471732959520] [llm] [INFO] [cpu_binding.py-238] : process 38738, new_affinity is [96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119], cpu count 24
[2025-10-28 16:42:50,038] [38741] [281467961035040] [llm] [INFO] [cpu_binding.py-212] : rank_id: 5, device_id: 5, numa_id: 0, shard_devices: [4, 5], cpus: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]
[2025-10-28 16:42:50,041] [38741] [281467961035040] [llm] [INFO] [cpu_binding.py-238] : process 38741, new_affinity is [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47], cpu count 24
[2025-10-28 16:42:50,070] [38740] [281470569695520] [llm] [INFO] [cpu_binding.py-212] : rank_id: 4, device_id: 4, numa_id: 0, shard_devices: [4, 5], cpus: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]
[2025-10-28 16:42:50,073] [38740] [281470569695520] [llm] [INFO] [cpu_binding.py-238] : process 38740, new_affinity is [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], cpu count 24
[2025-10-28 16:42:50,082] [38737] [281461271775520] [llm] [INFO] [cpu_binding.py-212] : rank_id: 1, device_id: 1, numa_id: 3, shard_devices: [0, 1], cpus: [144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191]
[2025-10-28 16:42:50,085] [38742] [281468354578720] [llm] [INFO] [cpu_binding.py-212] : rank_id: 6, device_id: 6, numa_id: 1, shard_devices: [6, 7], cpus: [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]
[2025-10-28 16:42:50,085] [38737] [281461271775520] [llm] [INFO] [cpu_binding.py-238] : process 38737, new_affinity is [168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191], cpu count 24
[2025-10-28 16:42:50,087] [38742] [281468354578720] [llm] [INFO] [cpu_binding.py-238] : process 38742, new_affinity is [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71], cpu count 24
[2025-10-28 16:42:54,706] [38736] [281459463375136] [llm] [INFO] [dist.py-81] : initialize_distributed has been Set
[2025-10-28 16:42:54,973] [38743] [281473109477664] [llm] [INFO] [dist.py-81] : initialize_distributed has been Set
[2025-10-28 16:42:55,034] [38739] [281460966443296] [llm] [INFO] [dist.py-81] : initialize_distributed has been Set
[2025-10-28 16:42:55,120] [38738] [281471732959520] [llm] [INFO] [dist.py-81] : initialize_distributed has been Set
[2025-10-28 16:42:55,982] [38740] [281470569695520] [llm] [INFO] [dist.py-81] : initialize_distributed has been Set
[2025-10-28 16:42:56,071] [38737] [281461271775520] [llm] [INFO] [dist.py-81] : initialize_distributed has been Set
[2025-10-28 16:42:56,126] [38741] [281467961035040] [llm] [INFO] [dist.py-81] : initialize_distributed has been Set
[2025-10-28 16:42:56,465] [38742] [281468354578720] [llm] [INFO] [dist.py-81] : initialize_distributed has been Set
[2025-10-28 16:43:53,499] [38736] [281459463375136] [llm] [INFO] [model_test.py-3150] : 24 pa_runner: PARunner(model_path=/data2/hf/models/deepseek-v3-bf16/, input_text=None, max_position_embeddings=3584, max_input_length=3072, max_output_length=512, max_prefill_tokens=-1, load_tokenizer=True, enable_atb_torch=False, max_prefill_batch_size=1, max_batch_size=1, dtype=torch.bfloat16, block_size=128, model_config=ModelConfig(num_heads=4, num_kv_heads=1, num_kv_heads_origin=128, head_size=576, k_head_size=576, v_head_size=0, num_layers=61, device=npu:0, dtype=torch.bfloat16, soc_info=NPUSocInfo(soc_name='', soc_version=223, need_nz=False, matmul_nd_nz=False), kv_quant_type=None, fa_quant_type=None, mapping=Mapping(world_size=32, rank=24, pp_rank=0, pp_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31]], micro_batch_size=1) , cla_share_factor=1, model_type=deepseekv2), max_memory=68719476736, 
[2025-10-28 16:43:53,499] [38736] [281459463375136] [llm] [INFO] [cache.py-102] : kv cache will allocate 0.23455810546875GB memory
[2025-10-28 16:43:56,243] [38738] [281471732959520] [llm] [INFO] [model_test.py-3150] : 26 pa_runner: PARunner(model_path=/data2/hf/models/deepseek-v3-bf16/, input_text=None, max_position_embeddings=3584, max_input_length=3072, max_output_length=512, max_prefill_tokens=-1, load_tokenizer=True, enable_atb_torch=False, max_prefill_batch_size=1, max_batch_size=1, dtype=torch.bfloat16, block_size=128, model_config=ModelConfig(num_heads=4, num_kv_heads=1, num_kv_heads_origin=128, head_size=576, k_head_size=576, v_head_size=0, num_layers=61, device=npu:2, dtype=torch.bfloat16, soc_info=NPUSocInfo(soc_name='', soc_version=223, need_nz=False, matmul_nd_nz=False), kv_quant_type=None, fa_quant_type=None, mapping=Mapping(world_size=32, rank=26, pp_rank=0, pp_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31]], micro_batch_size=1) , cla_share_factor=1, model_type=deepseekv2), max_memory=68719476736, 
[2025-10-28 16:43:56,243] [38738] [281471732959520] [llm] [INFO] [cache.py-102] : kv cache will allocate 0.23455810546875GB memory
[2025-10-28 16:43:57,156] [38737] [281461271775520] [llm] [INFO] [model_test.py-3150] : 25 pa_runner: PARunner(model_path=/data2/hf/models/deepseek-v3-bf16/, input_text=None, max_position_embeddings=3584, max_input_length=3072, max_output_length=512, max_prefill_tokens=-1, load_tokenizer=True, enable_atb_torch=False, max_prefill_batch_size=1, max_batch_size=1, dtype=torch.bfloat16, block_size=128, model_config=ModelConfig(num_heads=4, num_kv_heads=1, num_kv_heads_origin=128, head_size=576, k_head_size=576, v_head_size=0, num_layers=61, device=npu:1, dtype=torch.bfloat16, soc_info=NPUSocInfo(soc_name='', soc_version=223, need_nz=False, matmul_nd_nz=False), kv_quant_type=None, fa_quant_type=None, mapping=Mapping(world_size=32, rank=25, pp_rank=0, pp_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31]], micro_batch_size=1) , cla_share_factor=1, model_type=deepseekv2), max_memory=68719476736, 
[2025-10-28 16:43:57,156] [38737] [281461271775520] [llm] [INFO] [cache.py-102] : kv cache will allocate 0.23455810546875GB memory
Traceback (most recent call last):
  File "/usr/local/Ascend/atb-models/tests/modeltest/core/deepseekv2_test.py", line 43, in <module>
    main()
  File "/usr/local/Ascend/atb-models/tests/modeltest/core/deepseekv2_test.py", line 40, in main
    DeepseekV2ModelTest.create_instance()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 339, in create_instance
    test_instance.run()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 348, in run
    self.__run_multibs()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 400, in __run_multibs
    self.__run_single_bs()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 434, in __run_single_bs
    self.__run()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 573, in __run
    self.__run_precision()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 880, in __run_precision
    self.pa_runner.warm_up()
  File "/usr/local/Ascend/atb-models/examples/run_pa.py", line 241, in warm_up
    generate_req(req_list, self.model, self.max_batch_size, self.max_prefill_tokens, self.cache_manager)
  File "/usr/local/Ascend/atb-models/examples/server/generate.py", line 438, in generate_req
    req_finished, prefill_time = generate_token_with_clocking(model, cache_manager, batch)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/examples/server/generate.py", line 346, in generate_token_with_clocking
    req_finished = generate_token(model, cache_manager, input_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/examples/server/generate.py", line 278, in generate_token
    logits = model.forward(
             ^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/atb_llm/runner/model_runner.py", line 220, in forward
    return self.model.forward(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/atb_llm/models/base/flash_causal_lm.py", line 466, in forward
    logits = self.execute_ascend_operator(acl_inputs, acl_param, is_prefill)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/atb_llm/models/base/flash_causal_lm.py", line 418, in execute_ascend_operator
    acl_model_out = self.acl_encoder_operation.execute(acl_inputs, acl_param)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Setup fail, enable log: export ASDOPS_LOG_LEVEL=ERROR, export ASDOPS_LOG_TO_STDOUT=1 to find the first error. For more details, see the MindIE official document. 

[2025-10-28 16:43:59,181] [38739] [281460966443296] [llm] [INFO] [model_test.py-3150] : 27 pa_runner: PARunner(model_path=/data2/hf/models/deepseek-v3-bf16/, input_text=None, max_position_embeddings=3584, max_input_length=3072, max_output_length=512, max_prefill_tokens=-1, load_tokenizer=True, enable_atb_torch=False, max_prefill_batch_size=1, max_batch_size=1, dtype=torch.bfloat16, block_size=128, model_config=ModelConfig(num_heads=4, num_kv_heads=1, num_kv_heads_origin=128, head_size=576, k_head_size=576, v_head_size=0, num_layers=61, device=npu:3, dtype=torch.bfloat16, soc_info=NPUSocInfo(soc_name='', soc_version=223, need_nz=False, matmul_nd_nz=False), kv_quant_type=None, fa_quant_type=None, mapping=Mapping(world_size=32, rank=27, pp_rank=0, pp_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31]], micro_batch_size=1) , cla_share_factor=1, model_type=deepseekv2), max_memory=68719476736, 
[2025-10-28 16:43:59,181] [38739] [281460966443296] [llm] [INFO] [cache.py-102] : kv cache will allocate 0.23455810546875GB memory
[2025-10-28 16:44:00,097] [38740] [281470569695520] [llm] [INFO] [model_test.py-3150] : 28 pa_runner: PARunner(model_path=/data2/hf/models/deepseek-v3-bf16/, input_text=None, max_position_embeddings=3584, max_input_length=3072, max_output_length=512, max_prefill_tokens=-1, load_tokenizer=True, enable_atb_torch=False, max_prefill_batch_size=1, max_batch_size=1, dtype=torch.bfloat16, block_size=128, model_config=ModelConfig(num_heads=4, num_kv_heads=1, num_kv_heads_origin=128, head_size=576, k_head_size=576, v_head_size=0, num_layers=61, device=npu:4, dtype=torch.bfloat16, soc_info=NPUSocInfo(soc_name='', soc_version=223, need_nz=False, matmul_nd_nz=False), kv_quant_type=None, fa_quant_type=None, mapping=Mapping(world_size=32, rank=28, pp_rank=0, pp_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31]], micro_batch_size=1) , cla_share_factor=1, model_type=deepseekv2), max_memory=68719476736, 
[2025-10-28 16:44:00,097] [38740] [281470569695520] [llm] [INFO] [cache.py-102] : kv cache will allocate 0.23455810546875GB memory
[2025-10-28 16:44:01,013] [38742] [281468354578720] [llm] [INFO] [model_test.py-3150] : 30 pa_runner: PARunner(model_path=/data2/hf/models/deepseek-v3-bf16/, input_text=None, max_position_embeddings=3584, max_input_length=3072, max_output_length=512, max_prefill_tokens=-1, load_tokenizer=True, enable_atb_torch=False, max_prefill_batch_size=1, max_batch_size=1, dtype=torch.bfloat16, block_size=128, model_config=ModelConfig(num_heads=4, num_kv_heads=1, num_kv_heads_origin=128, head_size=576, k_head_size=576, v_head_size=0, num_layers=61, device=npu:6, dtype=torch.bfloat16, soc_info=NPUSocInfo(soc_name='', soc_version=223, need_nz=False, matmul_nd_nz=False), kv_quant_type=None, fa_quant_type=None, mapping=Mapping(world_size=32, rank=30, pp_rank=0, pp_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31]], micro_batch_size=1) , cla_share_factor=1, model_type=deepseekv2), max_memory=68719476736, 
[2025-10-28 16:44:01,014] [38742] [281468354578720] [llm] [INFO] [cache.py-102] : kv cache will allocate 0.23455810546875GB memory
Traceback (most recent call last):
  File "/usr/local/Ascend/atb-models/tests/modeltest/core/deepseekv2_test.py", line 43, in <module>
    main()
  File "/usr/local/Ascend/atb-models/tests/modeltest/core/deepseekv2_test.py", line 40, in main
    DeepseekV2ModelTest.create_instance()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 339, in create_instance
    test_instance.run()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 348, in run
    self.__run_multibs()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 400, in __run_multibs
    self.__run_single_bs()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 434, in __run_single_bs
    self.__run()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 573, in __run
    self.__run_precision()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 880, in __run_precision
    self.pa_runner.warm_up()
  File "/usr/local/Ascend/atb-models/examples/run_pa.py", line 241, in warm_up
    generate_req(req_list, self.model, self.max_batch_size, self.max_prefill_tokens, self.cache_manager)
  File "/usr/local/Ascend/atb-models/examples/server/generate.py", line 438, in generate_req
    req_finished, prefill_time = generate_token_with_clocking(model, cache_manager, batch)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/examples/server/generate.py", line 346, in generate_token_with_clocking
    req_finished = generate_token(model, cache_manager, input_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/examples/server/generate.py", line 278, in generate_token
    logits = model.forward(
             ^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/atb_llm/runner/model_runner.py", line 220, in forward
    return self.model.forward(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/atb_llm/models/base/flash_causal_lm.py", line 466, in forward
    logits = self.execute_ascend_operator(acl_inputs, acl_param, is_prefill)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/atb_llm/models/base/flash_causal_lm.py", line 418, in execute_ascend_operator
    acl_model_out = self.acl_encoder_operation.execute(acl_inputs, acl_param)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Setup fail, enable log: export ASDOPS_LOG_LEVEL=ERROR, export ASDOPS_LOG_TO_STDOUT=1 to find the first error. For more details, see the MindIE official document. 

Traceback (most recent call last):
  File "/usr/local/Ascend/atb-models/tests/modeltest/core/deepseekv2_test.py", line 43, in <module>
    main()
  File "/usr/local/Ascend/atb-models/tests/modeltest/core/deepseekv2_test.py", line 40, in main
    DeepseekV2ModelTest.create_instance()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 339, in create_instance
    test_instance.run()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 348, in run
    self.__run_multibs()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 400, in __run_multibs
    self.__run_single_bs()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 434, in __run_single_bs
    self.__run()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 573, in __run
    self.__run_precision()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 880, in __run_precision
    self.pa_runner.warm_up()
  File "/usr/local/Ascend/atb-models/examples/run_pa.py", line 241, in warm_up
    generate_req(req_list, self.model, self.max_batch_size, self.max_prefill_tokens, self.cache_manager)
  File "/usr/local/Ascend/atb-models/examples/server/generate.py", line 438, in generate_req
    req_finished, prefill_time = generate_token_with_clocking(model, cache_manager, batch)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/examples/server/generate.py", line 346, in generate_token_with_clocking
    req_finished = generate_token(model, cache_manager, input_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/examples/server/generate.py", line 278, in generate_token
    logits = model.forward(
             ^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/atb_llm/runner/model_runner.py", line 220, in forward
    return self.model.forward(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/atb_llm/models/base/flash_causal_lm.py", line 466, in forward
    logits = self.execute_ascend_operator(acl_inputs, acl_param, is_prefill)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/atb_llm/models/base/flash_causal_lm.py", line 418, in execute_ascend_operator
    acl_model_out = self.acl_encoder_operation.execute(acl_inputs, acl_param)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Setup fail, enable log: export ASDOPS_LOG_LEVEL=ERROR, export ASDOPS_LOG_TO_STDOUT=1 to find the first error. For more details, see the MindIE official document. 

[2025-10-28 16:44:01,944] [38741] [281467961035040] [llm] [INFO] [model_test.py-3150] : 29 pa_runner: PARunner(model_path=/data2/hf/models/deepseek-v3-bf16/, input_text=None, max_position_embeddings=3584, max_input_length=3072, max_output_length=512, max_prefill_tokens=-1, load_tokenizer=True, enable_atb_torch=False, max_prefill_batch_size=1, max_batch_size=1, dtype=torch.bfloat16, block_size=128, model_config=ModelConfig(num_heads=4, num_kv_heads=1, num_kv_heads_origin=128, head_size=576, k_head_size=576, v_head_size=0, num_layers=61, device=npu:5, dtype=torch.bfloat16, soc_info=NPUSocInfo(soc_name='', soc_version=223, need_nz=False, matmul_nd_nz=False), kv_quant_type=None, fa_quant_type=None, mapping=Mapping(world_size=32, rank=29, pp_rank=0, pp_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31]], micro_batch_size=1) , cla_share_factor=1, model_type=deepseekv2), max_memory=68719476736, 
[2025-10-28 16:44:01,944] [38741] [281467961035040] [llm] [INFO] [cache.py-102] : kv cache will allocate 0.23455810546875GB memory
[2025-10-28 16:44:02,854] [38743] [281473109477664] [llm] [INFO] [model_test.py-3150] : 31 pa_runner: PARunner(model_path=/data2/hf/models/deepseek-v3-bf16/, input_text=None, max_position_embeddings=3584, max_input_length=3072, max_output_length=512, max_prefill_tokens=-1, load_tokenizer=True, enable_atb_torch=False, max_prefill_batch_size=1, max_batch_size=1, dtype=torch.bfloat16, block_size=128, model_config=ModelConfig(num_heads=4, num_kv_heads=1, num_kv_heads_origin=128, head_size=576, k_head_size=576, v_head_size=0, num_layers=61, device=npu:7, dtype=torch.bfloat16, soc_info=NPUSocInfo(soc_name='', soc_version=223, need_nz=False, matmul_nd_nz=False), kv_quant_type=None, fa_quant_type=None, mapping=Mapping(world_size=32, rank=31, pp_rank=0, pp_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31]], micro_batch_size=1) , cla_share_factor=1, model_type=deepseekv2), max_memory=68719476736, 
[2025-10-28 16:44:02,855] [38743] [281473109477664] [llm] [INFO] [cache.py-102] : kv cache will allocate 0.23455810546875GB memory
Traceback (most recent call last):
  File "/usr/local/Ascend/atb-models/tests/modeltest/core/deepseekv2_test.py", line 43, in <module>
    main()
  File "/usr/local/Ascend/atb-models/tests/modeltest/core/deepseekv2_test.py", line 40, in main
    DeepseekV2ModelTest.create_instance()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 339, in create_instance
    test_instance.run()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 348, in run
    self.__run_multibs()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 400, in __run_multibs
    self.__run_single_bs()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 434, in __run_single_bs
    self.__run()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 573, in __run
    self.__run_precision()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 880, in __run_precision
    self.pa_runner.warm_up()
  File "/usr/local/Ascend/atb-models/examples/run_pa.py", line 241, in warm_up
    generate_req(req_list, self.model, self.max_batch_size, self.max_prefill_tokens, self.cache_manager)
  File "/usr/local/Ascend/atb-models/examples/server/generate.py", line 438, in generate_req
    req_finished, prefill_time = generate_token_with_clocking(model, cache_manager, batch)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/examples/server/generate.py", line 346, in generate_token_with_clocking
    req_finished = generate_token(model, cache_manager, input_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/examples/server/generate.py", line 278, in generate_token
    logits = model.forward(
             ^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/atb_llm/runner/model_runner.py", line 220, in forward
    return self.model.forward(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/atb_llm/models/base/flash_causal_lm.py", line 466, in forward
    logits = self.execute_ascend_operator(acl_inputs, acl_param, is_prefill)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/atb_llm/models/base/flash_causal_lm.py", line 418, in execute_ascend_operator
    acl_model_out = self.acl_encoder_operation.execute(acl_inputs, acl_param)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Setup fail, enable log: export ASDOPS_LOG_LEVEL=ERROR, export ASDOPS_LOG_TO_STDOUT=1 to find the first error. For more details, see the MindIE official document. 

Traceback (most recent call last):
  File "/usr/local/Ascend/atb-models/tests/modeltest/core/deepseekv2_test.py", line 43, in <module>
    main()
  File "/usr/local/Ascend/atb-models/tests/modeltest/core/deepseekv2_test.py", line 40, in main
    DeepseekV2ModelTest.create_instance()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 339, in create_instance
    test_instance.run()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 348, in run
    self.__run_multibs()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 400, in __run_multibs
    self.__run_single_bs()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 434, in __run_single_bs
    self.__run()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 573, in __run
    self.__run_precision()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 880, in __run_precision
    self.pa_runner.warm_up()
  File "/usr/local/Ascend/atb-models/examples/run_pa.py", line 241, in warm_up
    generate_req(req_list, self.model, self.max_batch_size, self.max_prefill_tokens, self.cache_manager)
  File "/usr/local/Ascend/atb-models/examples/server/generate.py", line 438, in generate_req
    req_finished, prefill_time = generate_token_with_clocking(model, cache_manager, batch)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/examples/server/generate.py", line 346, in generate_token_with_clocking
    req_finished = generate_token(model, cache_manager, input_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/examples/server/generate.py", line 278, in generate_token
    logits = model.forward(
             ^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/atb_llm/runner/model_runner.py", line 220, in forward
    return self.model.forward(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/atb_llm/models/base/flash_causal_lm.py", line 466, in forward
    logits = self.execute_ascend_operator(acl_inputs, acl_param, is_prefill)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/atb_llm/models/base/flash_causal_lm.py", line 418, in execute_ascend_operator
    acl_model_out = self.acl_encoder_operation.execute(acl_inputs, acl_param)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Setup fail, enable log: export ASDOPS_LOG_LEVEL=ERROR, export ASDOPS_LOG_TO_STDOUT=1 to find the first error. For more details, see the MindIE official document. 

Traceback (most recent call last):
  File "/usr/local/Ascend/atb-models/tests/modeltest/core/deepseekv2_test.py", line 43, in <module>
    main()
  File "/usr/local/Ascend/atb-models/tests/modeltest/core/deepseekv2_test.py", line 40, in main
    DeepseekV2ModelTest.create_instance()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 339, in create_instance
    test_instance.run()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 348, in run
    self.__run_multibs()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 400, in __run_multibs
    self.__run_single_bs()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 434, in __run_single_bs
    self.__run()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 573, in __run
    self.__run_precision()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 880, in __run_precision
    self.pa_runner.warm_up()
  File "/usr/local/Ascend/atb-models/examples/run_pa.py", line 241, in warm_up
    generate_req(req_list, self.model, self.max_batch_size, self.max_prefill_tokens, self.cache_manager)
  File "/usr/local/Ascend/atb-models/examples/server/generate.py", line 438, in generate_req
    req_finished, prefill_time = generate_token_with_clocking(model, cache_manager, batch)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/examples/server/generate.py", line 346, in generate_token_with_clocking
    req_finished = generate_token(model, cache_manager, input_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/examples/server/generate.py", line 278, in generate_token
    logits = model.forward(
             ^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/atb_llm/runner/model_runner.py", line 220, in forward
    return self.model.forward(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/atb_llm/models/base/flash_causal_lm.py", line 466, in forward
    logits = self.execute_ascend_operator(acl_inputs, acl_param, is_prefill)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/atb_llm/models/base/flash_causal_lm.py", line 418, in execute_ascend_operator
    acl_model_out = self.acl_encoder_operation.execute(acl_inputs, acl_param)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Setup fail, enable log: export ASDOPS_LOG_LEVEL=ERROR, export ASDOPS_LOG_TO_STDOUT=1 to find the first error. For more details, see the MindIE official document. 

Traceback (most recent call last):
  File "/usr/local/Ascend/atb-models/tests/modeltest/core/deepseekv2_test.py", line 43, in <module>
    main()
  File "/usr/local/Ascend/atb-models/tests/modeltest/core/deepseekv2_test.py", line 40, in main
    DeepseekV2ModelTest.create_instance()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 339, in create_instance
    test_instance.run()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 348, in run
    self.__run_multibs()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 400, in __run_multibs
    self.__run_single_bs()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 434, in __run_single_bs
    self.__run()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 573, in __run
    self.__run_precision()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 880, in __run_precision
    self.pa_runner.warm_up()
  File "/usr/local/Ascend/atb-models/examples/run_pa.py", line 241, in warm_up
    generate_req(req_list, self.model, self.max_batch_size, self.max_prefill_tokens, self.cache_manager)
  File "/usr/local/Ascend/atb-models/examples/server/generate.py", line 438, in generate_req
    req_finished, prefill_time = generate_token_with_clocking(model, cache_manager, batch)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/examples/server/generate.py", line 346, in generate_token_with_clocking
    req_finished = generate_token(model, cache_manager, input_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/examples/server/generate.py", line 278, in generate_token
    logits = model.forward(
             ^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/atb_llm/runner/model_runner.py", line 220, in forward
    return self.model.forward(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/atb_llm/models/base/flash_causal_lm.py", line 466, in forward
    logits = self.execute_ascend_operator(acl_inputs, acl_param, is_prefill)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/atb_llm/models/base/flash_causal_lm.py", line 418, in execute_ascend_operator
    acl_model_out = self.acl_encoder_operation.execute(acl_inputs, acl_param)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Setup fail, enable log: export ASDOPS_LOG_LEVEL=ERROR, export ASDOPS_LOG_TO_STDOUT=1 to find the first error. For more details, see the MindIE official document. 

Traceback (most recent call last):
  File "/usr/local/Ascend/atb-models/tests/modeltest/core/deepseekv2_test.py", line 43, in <module>
    main()
  File "/usr/local/Ascend/atb-models/tests/modeltest/core/deepseekv2_test.py", line 40, in main
    DeepseekV2ModelTest.create_instance()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 339, in create_instance
    test_instance.run()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 348, in run
    self.__run_multibs()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 400, in __run_multibs
    self.__run_single_bs()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 434, in __run_single_bs
    self.__run()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 573, in __run
    self.__run_precision()
  File "/usr/local/Ascend/atb-models/tests/modeltest/base/model_test.py", line 880, in __run_precision
    self.pa_runner.warm_up()
  File "/usr/local/Ascend/atb-models/examples/run_pa.py", line 241, in warm_up
    generate_req(req_list, self.model, self.max_batch_size, self.max_prefill_tokens, self.cache_manager)
  File "/usr/local/Ascend/atb-models/examples/server/generate.py", line 438, in generate_req
    req_finished, prefill_time = generate_token_with_clocking(model, cache_manager, batch)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/examples/server/generate.py", line 346, in generate_token_with_clocking
    req_finished = generate_token(model, cache_manager, input_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/examples/server/generate.py", line 278, in generate_token
    logits = model.forward(
             ^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/atb_llm/runner/model_runner.py", line 220, in forward
    return self.model.forward(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/atb_llm/models/base/flash_causal_lm.py", line 466, in forward
    logits = self.execute_ascend_operator(acl_inputs, acl_param, is_prefill)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Ascend/atb-models/atb_llm/models/base/flash_causal_lm.py", line 418, in execute_ascend_operator
    acl_model_out = self.acl_encoder_operation.execute(acl_inputs, acl_param)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Setup fail, enable log: export ASDOPS_LOG_LEVEL=ERROR, export ASDOPS_LOG_TO_STDOUT=1 to find the first error. For more details, see the MindIE official document. 

[ERROR] 2025-10-28-16:46:08 (PID:38742, Device:6, RankID:-1) ERR99999 UNKNOWN application exception
[ERROR] 2025-10-28-16:46:08 (PID:38741, Device:5, RankID:-1) ERR99999 UNKNOWN application exception
[ERROR] 2025-10-28-16:46:08 (PID:38740, Device:4, RankID:-1) ERR99999 UNKNOWN application exception
[ERROR] 2025-10-28-16:46:08 (PID:38737, Device:1, RankID:-1) ERR99999 UNKNOWN application exception
[ERROR] 2025-10-28-16:46:08 (PID:38739, Device:3, RankID:-1) ERR99999 UNKNOWN application exception
[ERROR] 2025-10-28-16:46:08 (PID:38738, Device:2, RankID:-1) ERR99999 UNKNOWN application exception
[ERROR] 2025-10-28-16:46:09 (PID:38736, Device:0, RankID:-1) ERR99999 UNKNOWN application exception
[ERROR] 2025-10-28-16:46:09 (PID:38743, Device:7, RankID:-1) ERR99999 UNKNOWN application exception
[2025-10-28 16:46:14,140] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 38736 closing signal SIGTERM
[2025-10-28 16:46:14,140] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 38737 closing signal SIGTERM
[2025-10-28 16:46:14,141] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 38739 closing signal SIGTERM
[2025-10-28 16:46:14,141] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 38740 closing signal SIGTERM
[2025-10-28 16:46:14,142] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 38742 closing signal SIGTERM
[2025-10-28 16:46:14,143] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 38743 closing signal SIGTERM
[2025-10-28 16:46:16,259] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 2 (pid: 38738) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/usr/local/lib64/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib64/python3.11/site-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib64/python3.11/site-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib64/python3.11/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib64/python3.11/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/usr/local/Ascend/atb-models/tests/modeltest/core/deepseekv2_test.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2025-10-28_16:46:14
  host      : gx4
  rank      : 29 (local_rank: 5)
  exitcode  : 1 (pid: 38741)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-10-28_16:46:14
  host      : gx4
  rank      : 26 (local_rank: 2)
  exitcode  : 1 (pid: 38738)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
something wrong marked for CI
precision test end marked for CI
